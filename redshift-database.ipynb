{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redshift Database Tutorial\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This tutorial will cover the basics of using the redshift database, which is loaded from the outputs of the DESI pipeline.  Currently, this is based on reference run 18.3, and uses a SQLite database.  However, by using [SQLAlchemy](http://www.sqlalchemy.org/), we abstract away the details of the database.  In other words only tiny changes to the initial configuration are needed to run the same code with a [PostgreSQL](https://www.postgresql.org/) database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "This just imports everything we need and sets up paths and environment variables so we can find things.  The paths are based on the [minitest notebook](https://github.com/desihub/desitest/blob/master/mini/minitest.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Imports\n",
    "#\n",
    "%matplotlib inline\n",
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import fontManager, FontProperties\n",
    "\n",
    "import desispec.database.redshift as db\n",
    "#\n",
    "# Paths to files, etc.\n",
    "#\n",
    "reference_run = '18.3'\n",
    "basedir = os.path.join('/global/project/projectdirs/desi/datachallenge/reference_runs', reference_run)\n",
    "surveydir = os.environ['DESISURVEY_OUTPUT'] = os.path.join(basedir, 'survey')\n",
    "targetdir = os.path.join(basedir, 'targets')\n",
    "fibassigndir = os.path.join(basedir, 'fiberassign')\n",
    "os.environ['DESI_SPECTRO_REDUX'] = os.path.join(basedir, 'spectro', 'redux')\n",
    "os.environ['DESI_SPECTRO_SIM'] = os.path.join(basedir, 'spectro', 'sim')\n",
    "os.environ['PIXPROD'] = 'mini'\n",
    "os.environ['SPECPROD'] = 'mini'\n",
    "reduxdir = os.path.join(os.environ['DESI_SPECTRO_REDUX'], os.environ['SPECPROD'])\n",
    "simdatadir = os.path.join(os.environ['DESI_SPECTRO_SIM'], os.environ['PIXPROD'])\n",
    "os.environ['DESI_SPECTRO_DATA'] = simdatadir\n",
    "#\n",
    "# Working directory.\n",
    "#\n",
    "workingdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Database\n",
    "\n",
    "Although there is already a database loaded from the 18.3 results, the schema of that database is already out-of-date, so we'll load a new database directly from the 18.3 files.  It should take less than one minute to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:redshift.py:724:setup_db: Removing file: /global/u2/b/bweaver/Documents/Code/git/desihub/tutorials/minitest-18.3.db.\n",
      "INFO:redshift.py:733:setup_db: Begin creating tables.\n",
      "INFO:redshift.py:737:setup_db: Finished creating tables.\n",
      "INFO:redshift.py:406:load_file: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/survey/exposures.fits.\n",
      "INFO:redshift.py:418:load_file: Integrity check complete on obslist.\n",
      "INFO:redshift.py:421:load_file: Initial column conversion complete on obslist.\n",
      "INFO:redshift.py:443:load_file: Column expansion complete on obslist.\n",
      "INFO:redshift.py:449:load_file: Column conversion complete on obslist.\n",
      "INFO:redshift.py:456:load_file: Converted columns into rows on obslist.\n",
      "INFO:redshift.py:463:load_file: Inserted 42 rows in obslist.\n",
      "INFO:redshift.py:406:load_file: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/targets/truth.fits.\n",
      "INFO:redshift.py:418:load_file: Integrity check complete on truth.\n",
      "INFO:redshift.py:421:load_file: Initial column conversion complete on truth.\n",
      "INFO:redshift.py:443:load_file: Column expansion complete on truth.\n",
      "INFO:redshift.py:449:load_file: Column conversion complete on truth.\n",
      "INFO:redshift.py:456:load_file: Converted columns into rows on truth.\n",
      "INFO:redshift.py:463:load_file: Inserted 50000 rows in truth.\n",
      "INFO:redshift.py:463:load_file: Inserted 100000 rows in truth.\n",
      "INFO:redshift.py:463:load_file: Inserted 150000 rows in truth.\n",
      "INFO:redshift.py:463:load_file: Inserted 200000 rows in truth.\n",
      "INFO:redshift.py:463:load_file: Inserted 240902 rows in truth.\n",
      "INFO:redshift.py:406:load_file: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/targets/targets.fits.\n",
      "INFO:redshift.py:418:load_file: Integrity check complete on target.\n",
      "INFO:redshift.py:421:load_file: Initial column conversion complete on target.\n",
      "INFO:redshift.py:443:load_file: Column expansion complete on target.\n",
      "INFO:redshift.py:449:load_file: Column conversion complete on target.\n",
      "INFO:redshift.py:456:load_file: Converted columns into rows on target.\n",
      "INFO:redshift.py:463:load_file: Inserted 50000 rows in target.\n",
      "INFO:redshift.py:463:load_file: Inserted 100000 rows in target.\n",
      "INFO:redshift.py:463:load_file: Inserted 150000 rows in target.\n",
      "INFO:redshift.py:463:load_file: Inserted 200000 rows in target.\n",
      "INFO:redshift.py:463:load_file: Inserted 240902 rows in target.\n",
      "INFO:redshift.py:406:load_file: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/spectro/redux/mini/zcatalog-mini.fits.\n",
      "INFO:redshift.py:418:load_file: Integrity check complete on zcat.\n",
      "INFO:redshift.py:421:load_file: Initial column conversion complete on zcat.\n",
      "INFO:redshift.py:443:load_file: Column expansion complete on zcat.\n",
      "INFO:redshift.py:449:load_file: Column conversion complete on zcat.\n",
      "INFO:redshift.py:456:load_file: Converted columns into rows on zcat.\n",
      "INFO:redshift.py:463:load_file: Inserted 44181 rows in zcat.\n",
      "INFO:redshift.py:562:load_fiberassign: Using tile file search path: /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_*.fits.\n",
      "INFO:redshift.py:567:load_fiberassign: Found 10 tile files.\n",
      "INFO:redshift.py:589:load_fiberassign: Identified 10 tile files for loading.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_16870.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 16870.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 16870.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 16870.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_06927.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 6927.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 6927.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 6927.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_01165.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 1165.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 1165.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 1165.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_11108.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 11108.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 11108.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 11108.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_24227.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 24227.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 24227.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 24227.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_34170.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 34170.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 34170.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 34170.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_39942.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 39942.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 39942.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 39942.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_28408.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 28408.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 28408.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 28408.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_45704.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 45704.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 45704.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 45704.\n",
      "INFO:redshift.py:597:load_fiberassign: Read data from /global/project/projectdirs/desi/datachallenge/reference_runs/18.3/fiberassign/tile_18465.fits.\n",
      "INFO:redshift.py:606:load_fiberassign: Initial column conversion complete on tileid = 18465.\n",
      "INFO:redshift.py:608:load_fiberassign: Converted columns into rows on tileid = 18465.\n",
      "INFO:redshift.py:612:load_fiberassign: Inserted 5000 rows in fiberassign for tileid = 18465.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We'll be using a SQLite database, ignore the return value of db.setup_db().\n",
    "#\n",
    "postgresql = db.setup_db(dbfile=os.path.join(workingdir, 'minitest-{0}.db'.format(reference_run)),\n",
    "                         overwrite=True)\n",
    "#\n",
    "# The list of exposures.\n",
    "# The expand option renames the column 'PASS' to 'passnum' in the database.\n",
    "# This is to prevent any collisions with the Python statement 'pass'.\n",
    "#\n",
    "db.load_file(os.path.join(surveydir, 'exposures.fits'), db.ObsList, hdu='EXPOSURES', expand={'PASS': 'passnum'})\n",
    "#\n",
    "# The truth and target tables.\n",
    "#\n",
    "db.load_file(os.path.join(targetdir, 'truth.fits'), db.Truth, hdu='TRUTH')\n",
    "db.load_file(os.path.join(targetdir, 'targets.fits'), db.Target, hdu='TARGETS')\n",
    "#\n",
    "# The redshift catalog.\n",
    "# In this case the expand option expands an array-valued column into corresponding scalar database columns.\n",
    "#\n",
    "db.load_file(os.path.join(reduxdir, 'zcatalog-mini.fits'), db.ZCat, hdu=\"ZCATALOG\",\n",
    "             expand={'COEFF': ('coeff_0', 'coeff_1', 'coeff_2', 'coeff_3', 'coeff_4',\n",
    "                               'coeff_5', 'coeff_6', 'coeff_7', 'coeff_8', 'coeff_9',)})\n",
    "#\n",
    "# The fiberassign outputs are not contained in a single file so a special loading function is needed.\n",
    "#\n",
    "db.load_fiberassign(fibassigndir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = db.dbSession.query(db.Truth, db.ZCat).filter(db.Truth.targetid == db.ZCat.targetid).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5218037366867065, 0.5214079152662674)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0][0].truez, q[0][1].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESI custom",
   "language": "python",
   "name": "desi-custom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
